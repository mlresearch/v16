---
section: studies
title: Managing Uncertainty within the KTD Framework
abstract: The dilemma between exploration and exploitation is an important topic in
  reinforcement learning (RL). Most successful approaches in addressing this problem
  tend to use some uncertainty information about values estimated during learning.
  On another hand, scalability is known as being a lack of RL algorithms and value
  function approximation has become a major topic of research. Both problems arise
  in real-world applications, however few approaches allow approximating the value
  function while maintaining uncertainty information about estimates. Even fewer use
  this information in the purpose of addressing the exploration/exploitation dilemma.
  In this paper, we show how such an uncertainty information can be derived from a
  Kalman-based Temporal Differences (KTD) framework and how it can be used.
pdf: "./geist11a/geist11a.pdf"
layout: inproceedings
key: geist11a
month: 0
firstpage: 157
lastpage: 168
origpdf: http://jmlr.org/proceedings/papers/v16/geist11a/geist11a.pdf
sections: 
authors:
- given: M.
  family: Geist
- given: O.
  family: Pietquin
---
